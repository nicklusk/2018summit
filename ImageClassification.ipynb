{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import argparse\n",
    "import random\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "IMAGE_DIMS = (64,64, 3)\n",
    "\n",
    "work_dir=os.getcwd()\n",
    "print(work_dir)\n",
    "\n",
    "saved_model=os.path.join(work_dir, 'detect_pills.model')\n",
    "saved_labels=os.path.join(work_dir, 'detect_pills.labels')\n",
    "\n",
    "trainingDatasetPath=os.path.join(work_dir, 'dataset/train')\n",
    "validationDatasetPath=os.path.join(work_dir, 'dataset/validation')\n",
    "\n",
    "imagePathsTrain = sorted(list(paths.list_images(trainingDatasetPath)))\n",
    "imagePathsValidate = sorted(list(paths.list_images(validationDatasetPath)))\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(imagePathsTrain)\n",
    "random.shuffle(imagePathsValidate)\n",
    "\n",
    "data_train = []\n",
    "labels_train = []\n",
    "pathes_train=[]\n",
    "data_validate = []\n",
    "labels_validate = []\n",
    "pathes_validate=[]\n",
    "\n",
    "def show_cv2_image(image, label):\n",
    "    RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(RGB_img)\n",
    "    plt.show()\n",
    "    print(label)\n",
    "    \n",
    "\n",
    "for imagePath in imagePathsTrain:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    l = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "    labels_train.append(l)\n",
    "    pathes_train.append(imagePath)\n",
    "    image = img_to_array(image)\n",
    "    data_train.append(image)\n",
    "\n",
    "for imagePath in imagePathsValidate:\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = img_to_array(image)\n",
    "    data_validate.append(image)\n",
    "    l = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
    "    labels_validate.append(l)\n",
    "    pathes_validate.append(imagePath)\n",
    "\n",
    "\n",
    "data_train = np.array(data_train, dtype=\"float\") / 255.0\n",
    "labels_train = np.array(labels_train)\n",
    "print(\"[INFO] Training Images: {} images ({:.2f}MB)\".format(len(imagePathsTrain), data_train.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "data_validate = np.array(data_validate, dtype=\"float\") / 255.0\n",
    "labels_validate = np.array(labels_validate)\n",
    "print(\"[INFO] Validation images: {} images ({:.2f}MB)\".format(len(imagePathsValidate), data_validate.nbytes / (1024 * 1000.0)))\n",
    "\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "labels_train = mlb.fit_transform(labels_train)\n",
    "labels_validate = mlb.fit_transform(labels_validate)\n",
    "\n",
    "print(\"[INFO] encoded labels:\")\n",
    "print(labels_train[:5]) \n",
    "\n",
    "print(\"[INFO] classes:\")\n",
    "for (i, label) in enumerate(mlb.classes_):\n",
    "    print(\"{}. {}\".format(i + 1, label))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras.applications import VGG16\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "\n",
    "EPOCHS = 40\n",
    "INIT_LR = 3e-4\n",
    "BS = 40\n",
    "VALIDATION_STEPS=50\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',input_shape=(IMAGE_DIMS[0], IMAGE_DIMS[1], IMAGE_DIMS[2])))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.0005),\n",
    "                activity_regularizer=regularizers.l1(0.0005)))\n",
    "model.add(layers.Dense(6, activation='softmax'))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0,height_shift_range=0, shear_range=0, \n",
    "                         zoom_range=0,horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=INIT_LR),\n",
    "              metrics=['categorical_accuracy'])\n",
    "history = model.fit_generator(aug.flow(data_train, labels_train, batch_size=BS),\n",
    "                              validation_data=(\n",
    "                                  data_validate, labels_validate),\n",
    "                              steps_per_epoch=len(data_train),\n",
    "                              epochs=EPOCHS,\n",
    "                              validation_steps=VALIDATION_STEPS,\n",
    "                              verbose=1)\n",
    "\n",
    "model.save(saved_model)\n",
    "\n",
    "print(\"[INFO] serializing label binarizer...\")\n",
    "f = open(saved_labels, \"wb\")\n",
    "f.write(pickle.dumps(mlb))\n",
    "f.close()\n",
    "\n",
    "(eval_loss, eval_accuracy) = model.evaluate(data_validate, labels_validate, batch_size=len(data_train), verbose=1)\n",
    "\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))\n",
    "\n",
    "print(history.history.keys())\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "# summarize history for accuracy\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.plot(history.history['categorical_accuracy'])\n",
    "plt.plot(history.history['val_categorical_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "\n",
    "# summarize history for loss\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from imutils import paths\n",
    "\n",
    "saved_model=os.path.join(work_dir, 'detect_pills.model')\n",
    "saved_labels=os.path.join(work_dir, 'detect_pills.labels')\n",
    "testDatasetPath=os.path.join(work_dir, 'dataset\\\\test')\n",
    "\n",
    "imagePaths = sorted(list(paths.list_images(testDatasetPath)))\n",
    "\n",
    "print(\"[INFO] loading network...\")\n",
    "model = load_model(saved_model)\n",
    "mlb = pickle.loads(open(saved_labels, \"rb\").read())\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    image = cv2.imread(imagePath)\n",
    "    RGB_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(RGB_img)\n",
    "    plt.show()\n",
    "    output = imutils.resize(image, width=300)\n",
    "\n",
    "    # pre-process the image for classification\n",
    "    image = cv2.resize(image, (64, 64))\n",
    "    image = image.astype(\"float\") / 255.0\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    print(\"[INFO] classifying image...\")\n",
    "    proba = model.predict(image)[0]\n",
    "    \n",
    "    print (imagePath)\n",
    "    # show the probabilities for each of the individual labels\n",
    "    for (label, p) in zip(mlb.classes_, proba):\n",
    "        print(\"{}: {:.2f}%\".format(label, p * 100))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
